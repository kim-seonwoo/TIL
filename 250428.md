![image.png](attachment:c3c93e02-7eee-4d71-8482-de093869533e:image.png)

# 1. 인공지능 개요

## 지능이란?

![image.png](attachment:c6c56fdd-df2e-4dcf-b646-90c156d094a0:image.png)

# 2. 탐색 개요

## 탐색

우리가 선택할 수 있는 보기 중에서 여러가지 판단을 고려해 최종 선택을 하게 되는 과정을 탐색이라고 한다.

컴퓨터의 경우, 문제를 잘 정형화된 형식으로 잘 표현해 주어야 한다.
한국어(정황어), 영어(위치어)

## 문제 정의의 기본 요소

문제 정의의 기본 요소

- 상태(States): 주어진 문제의 자료 구조
- 초기 상태(Initial state): 문제가 주어진 시작 시점의 상태
- 목표 상태(Goal state): 문제에서 원하는 최종 목표의 상태
- 연산(Operator): 특정 상태에서 움직일 수 있는 동작에 대한 설명
- 상태 공간(State space): 초기 상태로부터 연산을 통해 도달할 수 있는 모든 결과(상태)들의 공간(집합)
- 경로(Path): 특정 상태에서 다른 상태로 이끄는 일련의 행동(action)
- 경로 비용 함수(Path cost function): 목표 상태까지 도달하는 경로(path)에 비용(cost)을 할당하는 함수
- 목표 테스트(Goal test): 목표 상태에 도달하였는지 확인하는 작업
- 문제의 해(solution): 초기 상태에서 목표 상태까지의 경로

## 퍼즐 예시

- blank 중심으로 하게 되면 기존의 전체를 다 고려하는 방식에 비해 오퍼레이터 사용 효율이 좋다. (path cost = 5)

## 상태 공간 그래프와 탐색 트리

- node: 상태 (State)
- edge: 행동(action)
- 상태 변화 그래프: 상태 공간에서 각 행동에 따른 상태 변화를 나타낸 그래프이다.
- 탐색 트리 : 상태 공간 그래프의 초기상태(S)에서 화살표 방향으로 이동하는 연산을 통해 탐색한 모든 경로를 표시하면 아래와 같은 탐색 트리로 구성 가능.
- 상태 공간 그래프로 탐색 트리 만들어보기! (차근 차근)

![image.png](attachment:b8fdfaac-5b49-4053-99f5-29027e46b07c:image.png)

- [그림 5]의 ‘상태 공간 그래프’는 비교적 간단한 형태이기 때문에 [그림 6]처럼 나올 수 있는 모든 경우에 대한 탐색
  경로를 ‘탐색 트리’로 작성이 가능하지만, 일반적인 문제에서는 상태 공간이 매우 큰 경우가 대부분이다.
- 8-Puzzle 문제의 경우에도 나올 수 있는 모든 상태의 수가 362,880(=9!)개 이다.
  • 즉, 일반적으로 모든 상태 정보를 이용할 수 없고, 탐색 트리 전체를 한번에 그려 모든 경우의 수를 고려해 문제를
  푸는 것은 거의 불가능하다.
  • 이러한 상황을 고려하여 주어진 문제를 풀기 위해 일정한 규칙을 따르거나, 진행 과정의 상태에서 활용할 수 있는
  정보를 이용해 ‘상태 공간 그래프’를 조금씩 확장하면서 문제의 답을 찾는 방법을 고민하게 되었다. (맹목적 탐색, 휴리스틱 탐색)

# 3. 맹목적 탐색

## 맹목적 탐색

- 어떠한 상태 공간의 정보도 이용하지 않고 단순히 정해진 순서에 따라 탐색 트리를 작성하며 해를 찾아가는 방법이다.
- 초기 상태로부터 확장하는 과정에서 선택하는 전략(정해진 방법)에 따라 너비 우선 탐색, 깊이 우선 탐색, 반복적 깊이 심화 탐색, 양방향 탐색 등으로 나뉜다.

## 너비 우선 탐색 (BFS)

- 초기 상태인 루트 노드에서 시작하여 목표 상태에 도달할 때 까지 매 단계마다 확장 가능한 상태로 모든 자식 노드를 생성하는 방법이다.
- 매번 전체 노드를 훑고 지나간다.

![image.png](attachment:4a133a19-27dd-4dd8-8005-e88a9cbfcb8b:image.png)

Goal과 맞지 않으면 킵하고 넘어감, 이전 방법을 제외한 갈 수 있는 곳으로 확장

- 너비 우선 탐색의 경우 초기상태에서 목표상태까지 도달하는 최적(최단) 경로(Optimal Path)를 보장하는 장점이 있다.
  • 다만 탐색과정에서 나타나는 모든 상태를 저장시켜야 하기 때문에 메모리 활용 관점에서는 부담이 큰 방법이다.

## 깊이 우선 탐색

- 초기 루트 노드에서 시작하여 매 단계에서 하나의 자식 노드만 선택하여 탐색하는 방법이다. (하나의 경로 유지)
- max-depth 다다르면 제거하고 다시 올라감
- 깊이 우선 탐색의 경우 백트래킹 과정에서 목표 상태로 도달에 실패한 경로를 제거하는 과정을 거쳐 현재 확장중인
  경로만 저장하게 된다. 즉, 메모리 활용에 있어 부담이 적은 장점이 있다. 다만 목표 상태까지 도달한 탐색의 결과(해)가 최적(최단) 경로(Optimal Path)라는 보장을 할 수 없는 것이 단점이다.

## 반복적 깊이 심화 탐색

- 반복적 깊이 심화 탐색(Iterative Deeping Search): 깊이 한계(depth limit)를 0부터 1씩 점차 증가시키면서
  깊이 우선 탐색을 반복적으로 적용하는 방법이다.
  • 기본적으로 깊이 우선 탐색이기 때문에 메모리 부담이 적다 (기억을 적게 해도된다). 다만 걱정할 수 있는 부분은 깊이가 증가할
  때마다 루트 노드(root node)부터 새로 탐색을 진행하게 되어 비효율적인 면이 있다는 점인데 이는 크게
  부담되지 않는 정도이다.
- 예를 들어 각 부모 노드(parent node)가 10개의 자식 노드(child node)를 갖는 경우 반복적 깊이 심화
  탐색은 너비 우선 탐색에 비해 약 11% 정도의 노드만 추가로 생성하는 정도에 불과하다.

## 양방향 탐색

- 초기 상태에서 시작해 목표 상태 방향으로만 확장하는 다른 방법들과 달리 양방향 탐색은 초기 상태와 목표 상태에서
  동시에 너비우선 탐색을 진행하면서 중간에서 만나도록해 최적(최단) 경로(Optimal Path)를 찾는 방법이다. 너비 우선 탐색보다 훨씬 적은 수의 노드를 생성하기 때문에 메모리 부담이 적고 탐색에 걸리는 시간 역시 짧다.
      ![스크린샷 2025-04-28 오후 3.10.33.png](attachment:92987c29-ac2d-486d-ad07-aa89f9ff1906:스크린샷_2025-04-28_오후_3.10.33.png)

# 4. 휴리스틱 탐색

# 6. 최적화

- 우리가 얻을 수 있는 정답 중에서 주어진 기준을 가장 잘 만족시키는 정답을 최적해라고 한다. 이러한 최적해를 찾는 것을 최적화라고 한다.

## 조합 최적화

- 해가 주어진 항목들의 조합으로 표현되는 문제에 대한 최적화 방법이다. 준최적의 느낌으로 일정 기준을 넘기는.

### 유전 알고리즘

- 자연세계의 진화과정에 기초한 계산 알고리즘.
- 팩토리얼로 진행된다.

### 적합도 함수

- 적합한 답이라는 기준

![image.png](attachment:3659c883-4ca4-41a7-87c5-5cde46d3fb62:image.png)

![image.png](attachment:18f68aff-d22b-4839-8048-f2454bdbcc1e:image.png)

![image.png](attachment:4701619b-2c55-4ffc-99fd-4169075dc839:image.png)

![image.png](attachment:c4b6a9a3-b1bf-4b0b-858a-3f27bb40d533:image.png)

![image.png](attachment:55a99d93-bc60-4e75-a90d-5ad2e84023ad:image.png)

![image.png](attachment:03f92cd5-752c-4b4f-bea7-7de93de063c2:image.png)

- mutation 돌연변이 발생 하나의 위치에서

![image.png](attachment:62c5901f-ab53-4af3-8c7c-cdd7df9d8ce5:image.png)

1. 초기 모집단 생성
2. 적합도 평가
3. 부모 개체 선택
4. 자식 개체 생성
5. 새로운 모집단 구성 및 적합도 평가

## 함수 최적화

함수 최적화(Function Optimization): 어떤 함수가 있을때 원하는 최적의 상태(최대 또는 최소)로 만드는 변수값(파라미터)을 찾는 방법이다. 이때 최적화의 대상이 되는 함수를 목적함수(Objective Function)라고 한다.

![image.png](attachment:5b1244b2-8bd7-4c34-b1e9-14226c0c0a68:image.png)

점에서 선의 오차가 최소가 되어야 한다.

- 목적함수를 찾으려면 오차가 메인 포인트 이고, B0와 B1을 찾아야한다.
- 찾으려면 최소 제곱법을 사용해야함, 이것은 미분을 이용함.

![image.png](attachment:c83b9117-9be5-4a4d-98f4-116cc2e692d9:image.png)

![image.png](attachment:2ac59c9d-5cb6-4541-b489-b8990a07675e:image.png)

1번 2번 0 equal로 놓고 연립하여 푼다. B0과 B1을 구하기 위해

- 경사하강법: 기울기의 반대 방향으로 조금씩 움직이면서 최적화 시킴

![image.png](attachment:28e2bd0f-473b-4b58-8cbc-4025e60e7b88:image.png)

- 경사하강법 움직이는 정도는 학습률.
  매우 큰 경우 최적해를 지나갈수도 있고, 적으면 비효율적임

그렇다면 경사하강법 사용 시 기울기의 반대방향으로 얼마만큼 움직일 수
있느냐에 대한 고민을 해볼 수 있다. 움직이는 정도를 학습률(learning rate)라
부르며 이는 한번에 변수를 이동시키는 정도를 뜻한다. 학습률이 아주 작으면
조금씩 여러번 움직여야하고, 학습률이 매우 큰 경우 최적해를 지나가버릴 수도 있다.

- 전역최소값, 지역최소값
  수렴이 되었을때 시프트를 강하게 한번 줌

또한 앞의 예시처럼 간단한 함수 형태의 경우 시작 지점이 어디든지 한 지점을 향해 가지만 여러개의 지역적 최적해가 존재하는 경우 실제 우리가 찾은 해가 목적함수 전체에서 최적의 해가 아닌 경우가 발생하게 된다. 그렇기 떄문에 경사하강법을 사용하는 경우 여러개의 시작값을 적용해 결과를 비교 확인해 볼 필요가 있다.

#
